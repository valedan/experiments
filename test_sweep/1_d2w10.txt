2024-08-07 17:58:13 - Starting run 1
2024-08-07 17:58:14 - Train set: 600, Val set: 600
2024-08-07 17:58:14 - Starting epoch 1/5
2024-08-07 17:58:15 - Batch 0 - Train Loss 18.6624 - Val Loss 37.9079
2024-08-07 17:58:15 - Batch 1 - Train Loss 38.3764 - Val Loss 15.7960
2024-08-07 17:58:15 - Batch 2 - Train Loss 13.3975 - Val Loss 9.1478
2024-08-07 17:58:15 - Batch 3 - Train Loss 9.6576 - Val Loss 8.8235
2024-08-07 17:58:15 - Batch 4 - Train Loss 8.4303 - Val Loss 12.6032
2024-08-07 17:58:15 - Batch 5 - Train Loss 13.1529 - Val Loss 7.2958
2024-08-07 17:58:15 - Batch 6 - Train Loss 5.7231 - Val Loss 7.4211
2024-08-07 17:58:15 - Batch 7 - Train Loss 5.4761 - Val Loss 5.0075
2024-08-07 17:58:15 - Batch 8 - Train Loss 4.9162 - Val Loss 2.9211
2024-08-07 17:58:15 - Batch 9 - Train Loss 2.4240 - Val Loss 2.7612
2024-08-07 17:58:15 - Starting epoch 2/5
2024-08-07 17:58:15 - Batch 0 - Train Loss 2.2285 - Val Loss 2.6862
2024-08-07 17:58:16 - Batch 1 - Train Loss 2.4528 - Val Loss 2.5253
2024-08-07 17:58:16 - Batch 2 - Train Loss 1.7039 - Val Loss 2.2744
2024-08-07 17:58:16 - Batch 3 - Train Loss 2.2057 - Val Loss 2.1773
2024-08-07 17:58:16 - Batch 4 - Train Loss 1.8613 - Val Loss 2.5194
2024-08-07 17:58:16 - Batch 5 - Train Loss 1.8066 - Val Loss 2.2246
2024-08-07 17:58:21 - RuntimeError: DataLoader worker (pid(s) 3087922, 3087954) exited unexpectedly
Traceback (most recent call last):
  File "/home/dan/projects/exploration/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1131, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dan/.pyenv/versions/3.12.4/lib/python3.12/multiprocessing/queues.py", line 114, in get
    raise Empty
_queue.Empty

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/dan/projects/exploration/infra/runner.py", line 43, in start
    await self.run_func(self.logger, self.params)
  File "/home/dan/projects/exploration/experiments/mnist/experiment.py", line 112, in train_classifier
    for i, val_batch in enumerate(val_loader):
  File "/home/dan/projects/exploration/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/dan/projects/exploration/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1327, in _next_data
    idx, data = self._get_data()
                ^^^^^^^^^^^^^^^^
  File "/home/dan/projects/exploration/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1293, in _get_data
    success, data = self._try_get_data()
                    ^^^^^^^^^^^^^^^^^^^^
  File "/home/dan/projects/exploration/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1144, in _try_get_data
    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e
RuntimeError: DataLoader worker (pid(s) 3087922, 3087954) exited unexpectedly

2024-08-07 17:59:03 - Starting run 1
2024-08-07 17:59:04 - Train set: 600, Val set: 600
2024-08-07 17:59:05 - Starting epoch 1/5
2024-08-07 17:59:05 - Batch 0 - Train Loss 16.0082 - Val Loss 52.5097
2024-08-07 17:59:05 - Batch 1 - Train Loss 48.8406 - Val Loss 22.2491
2024-08-07 17:59:05 - Batch 2 - Train Loss 23.2085 - Val Loss 11.8039
2024-08-07 17:59:05 - Batch 3 - Train Loss 11.7488 - Val Loss 17.1173
2024-08-07 17:59:05 - Batch 4 - Train Loss 14.7089 - Val Loss 35.5834
2024-08-07 17:59:05 - Batch 5 - Train Loss 37.9077 - Val Loss 19.6693
2024-08-07 17:59:05 - Batch 6 - Train Loss 16.4655 - Val Loss 11.2628
2024-08-07 17:59:06 - Batch 7 - Train Loss 8.7228 - Val Loss 6.3399
2024-08-07 17:59:06 - Batch 8 - Train Loss 7.5611 - Val Loss 6.8484
2024-08-07 17:59:06 - Batch 9 - Train Loss 7.4174 - Val Loss 3.9095
2024-08-07 17:59:06 - Starting epoch 2/5
2024-08-07 17:59:06 - Batch 0 - Train Loss 3.4484 - Val Loss 3.0797
2024-08-07 17:59:06 - Batch 1 - Train Loss 2.6743 - Val Loss 3.0728
2024-08-07 17:59:06 - Batch 2 - Train Loss 3.0744 - Val Loss 2.7558
2024-08-07 18:00:58 - Starting run 1
2024-08-07 18:00:59 - Train set: 600, Val set: 600
2024-08-07 18:00:59 - Starting epoch 1/5
2024-08-07 18:00:59 - Batch 0 - Train Loss 10.4679 - Val Loss 19.0914
2024-08-07 18:01:00 - Batch 1 - Train Loss 17.3043 - Val Loss 19.7152
2024-08-07 18:01:00 - Batch 2 - Train Loss 19.0389 - Val Loss 32.8937
2024-08-07 18:01:00 - Batch 3 - Train Loss 32.5911 - Val Loss 10.5264
2024-08-07 18:01:00 - Batch 4 - Train Loss 9.9265 - Val Loss 7.5289
2024-08-07 18:01:00 - Batch 5 - Train Loss 8.3617 - Val Loss 4.6721
2024-08-07 18:01:00 - Batch 6 - Train Loss 6.2064 - Val Loss 3.5975
2024-08-07 18:01:00 - Batch 7 - Train Loss 3.5790 - Val Loss 2.8958
2024-08-07 18:01:00 - Batch 8 - Train Loss 1.8211 - Val Loss 2.0821
2024-08-07 18:01:00 - Batch 9 - Train Loss 2.4851 - Val Loss 5.5708
2024-08-07 18:01:00 - Starting epoch 2/5
2024-08-07 18:01:00 - Batch 0 - Train Loss 4.7638 - Val Loss 4.2563
2024-08-07 18:01:00 - Batch 1 - Train Loss 4.0087 - Val Loss 3.7336
2024-08-07 18:01:00 - Batch 2 - Train Loss 3.4392 - Val Loss 3.1451
2024-08-07 18:01:01 - Batch 3 - Train Loss 2.8315 - Val Loss 2.5956
2024-08-07 18:01:01 - Batch 4 - Train Loss 2.6244 - Val Loss 1.8669
2024-08-07 18:01:01 - Batch 5 - Train Loss 1.8226 - Val Loss 1.6059
2024-08-07 18:01:01 - Batch 6 - Train Loss 1.6929 - Val Loss 1.9089
2024-08-07 18:01:01 - Batch 7 - Train Loss 1.6247 - Val Loss 1.7894
2024-08-07 18:01:01 - Batch 8 - Train Loss 1.8459 - Val Loss 1.8608
2024-08-07 18:01:01 - Batch 9 - Train Loss 1.6227 - Val Loss 1.7365
2024-08-07 18:01:01 - Starting epoch 3/5
2024-08-07 18:01:01 - Batch 0 - Train Loss 1.2253 - Val Loss 1.5646
2024-08-07 18:01:01 - Batch 1 - Train Loss 1.5581 - Val Loss 1.5323
2024-08-07 18:01:01 - Batch 2 - Train Loss 1.4835 - Val Loss 1.5468
2024-08-07 18:01:01 - Batch 3 - Train Loss 1.9673 - Val Loss 1.3915
2024-08-07 18:01:02 - Batch 4 - Train Loss 0.8361 - Val Loss 1.4264
2024-08-07 18:01:02 - Batch 5 - Train Loss 0.7569 - Val Loss 1.3827
2024-08-07 18:01:02 - Batch 6 - Train Loss 1.1268 - Val Loss 1.3741
2024-08-07 18:01:02 - Batch 7 - Train Loss 1.2387 - Val Loss 1.3723
2024-08-07 18:01:02 - Batch 8 - Train Loss 1.2217 - Val Loss 1.3856
2024-08-07 18:01:02 - Batch 9 - Train Loss 0.6873 - Val Loss 1.3884
2024-08-07 18:01:02 - Starting epoch 4/5
2024-08-07 18:01:02 - Batch 0 - Train Loss 1.1799 - Val Loss 1.3722
2024-08-07 18:01:02 - Batch 1 - Train Loss 0.8660 - Val Loss 1.2758
2024-08-07 18:01:02 - Batch 2 - Train Loss 0.9473 - Val Loss 1.3186
2024-08-07 18:01:02 - Batch 3 - Train Loss 0.7438 - Val Loss 1.2434
2024-08-07 18:01:02 - Batch 4 - Train Loss 1.0106 - Val Loss 1.2871
2024-08-07 18:01:03 - Batch 5 - Train Loss 0.7983 - Val Loss 1.3047
2024-08-07 18:01:03 - Batch 6 - Train Loss 1.0013 - Val Loss 1.2826
2024-08-07 18:01:03 - Batch 7 - Train Loss 0.9570 - Val Loss 1.2587
2024-08-07 18:01:03 - Batch 8 - Train Loss 0.9800 - Val Loss 1.2361
2024-08-07 18:01:03 - Batch 9 - Train Loss 1.0001 - Val Loss 1.5124
2024-08-07 18:01:03 - Starting epoch 5/5
2024-08-07 18:01:03 - Batch 0 - Train Loss 0.9235 - Val Loss 1.1884
2024-08-07 18:01:03 - Batch 1 - Train Loss 1.0766 - Val Loss 1.2429
2024-08-07 18:01:03 - Batch 2 - Train Loss 0.6537 - Val Loss 1.1114
2024-08-07 18:01:03 - Batch 3 - Train Loss 0.8095 - Val Loss 1.1413
2024-08-07 18:01:03 - Batch 4 - Train Loss 1.1560 - Val Loss 1.2001
2024-08-07 18:01:03 - Batch 5 - Train Loss 0.9711 - Val Loss 1.2364
2024-08-07 18:01:04 - Batch 6 - Train Loss 0.8709 - Val Loss 1.2088
2024-08-07 18:01:04 - Batch 7 - Train Loss 0.5415 - Val Loss 1.2574
2024-08-07 18:01:04 - Batch 8 - Train Loss 0.9592 - Val Loss 1.2716
2024-08-07 18:01:04 - Batch 9 - Train Loss 0.4827 - Val Loss 1.1314
2024-08-07 18:01:04 - Finished run 1
